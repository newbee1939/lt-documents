---
marp: true
theme: gaia
class: invert
footer: "2023/11/17 AIのLT会"
size: 16:9
paginate: true
style: |
  img[alt='center'] {
      display: block;
      margin: 0 auto;
  }
---

<!--
_class:
    - lead
    - invert
_footer: ""
_paginate: false
-->

# ChatGPT の頭の中を

# 少しだけ覗いてみた

---

<!--
_class:
    - invert
_footer: ""
-->

# 参考にした本

![w:312 center](chat.jpg)

---

# ChatGPT とは？

- OpenAI が開発した自然言語処理の人工知能モデル
- コンピュータとの対話やテキスト生成など、さまざまな言語タスクに利用できる

![w:510](gpt.png)

---

# ChatGPT は何をしているのか？

- 基本的には、一つずつ単語を足しているだけ
- ChatGPT は基本的に、そこまで出力された内容の「順当な続き」を出力しようと試みる
- 「順当」とは、「億単位のウェブページなどに書かれている内容を見たうえで人間が書きそうだと予測される」という意味

---

# 「順当な続き」はどう求めるのか？

- 基本的には「確率」に従っているだけ
- 例えば、「AI の一番の長所としてあげられるのは」という書きかけの文があるとする
- 人間が書いた億単位の文章を（ウェブページや電子書籍などから）スキャンして、この一文が出現するあらゆるケースを見つけ、どの単語がどのくらいの確率で次に続くかを調べる
- 確率の高い答えを出力する

---

# 例えば

- 「AI の一番の長所としてあげられるのは、スピードと効率の向上です」
  - 5%
- 「AI の一番の長所としてあげられるのは、無人・危険な作業への適用です」
  - 3%
- 基本的には、確率の高い「AI の一番の長所としてあげられるのは、スピードと効率の向上です」を出力する

---

# ただし

- 毎回「確率の高い」単語のみを選んでいたら、面白みのない単調な文章になってしまう
- ランクの低い単語を使う頻度を決める「温度」というパラメーターを設定することで、ChatGPT に創造性とランダム性が与えられる
- 高い温度はより多くの乱雑さを生み出し、低い温度はより予測可能かつ安全な出力をもたらす

---

# 確率はどうやって求めるのか？

- 実際には、全ての単語の組み合わせを考えることは不可能
- 現存するコーパスに含まれるテキストでは単語の組み合わせを実際にはっきりと確認できないとしても、その組み合わせが出現する確率を推定してくれる「モデル」を作ればいいのではないか
- ChatGPT の中心になっているのが、そのような確率の推定をうまく処理するように設計されたモデル「大規模言語モデル(LLM)」である
- 統計的な法則を使用して現実的な言葉の組み合わせを学ぶ
- ここで使用されるのが「大規模言語モデル（LLM）」と呼ばれる深層学習モデル
- このモデルは膨大なデータから事前学習され、全ての言葉の組み合わせを考える代わりに、統計的な学習を通じて言語のパターンを捉える

---

# 「モデル」とは何か？

- 「現実の複雑なシステムや現象を簡略化して表現するための枠組みや仮説」のこと
- 例えば、落下させる高さによって下に落ちるまでの時間を計算することを考える
- もちろん実際に試して計算することもできるが、ある程度の数を試せば、計算式を作って、その他の高さから落とした場合の時間も求めることができる
- この「計算式」のようなものが「モデル」

---

- ChatGPT は LLM というモデルを使って動いている
- LLM というモデルを使うことで、実際の全ての単語の組み合わせを計算せずとも、確率的に可能性が高い単語を選択できる

---

# 「ニューラルネット」について

- 前節で説明したのは、基本的に単純な物理学に由来する数値データのモデルを作るという例であり、いってみれば「単純な数学が当てはまる」ことが何世紀も前から分かっている例だった
- それに対して ChatGPT の場合は、人の脳によって作り出されるのと同じような自然言語の文章に対応するモデルを作らなければならない
- ChatGPT のベースにあるのは、ニューラルネットという概念

- LLM には、ベースとなるモデルが存在する
- 「ニューラルネットワーク」と呼ばれる人間の脳のニューロンの働きを模倣する計算モデル
- 人間の脳のはたらきを単純に理想化したもの

---

本の後半ではニューラルネットについて色々説明してあるらしいけどまだ読めていない。。

---

# まとめ

- ChatGPT とは OpenAI が開発した自然言語処理の人工知能モデル
- 確率に基づいて高い予測確率の単語を選択
- 「温度」というパラーメーターによってランダム性も付与している
- 現実的な言葉の組み合わせを学習するために「大規模言語モデル（LLM）」を使用
  - LLM は統計的な学習を通じて言語パターンを捉える
- ChatGPT は「ニューラルネット」を基盤のモデルとして採用している

---

# 感想

- 「確率」に基づいて単語を選択しているというのは知らなかったのでなるほどと思った
- ChatGPT が精度の低い回答を返す理由や毎回同じ回答を返すわけではない理由がふんわり分かったのも良かった
- ただ、「ニューラルネット？？」みたいな状態なので、もう少し深めたい気持ちはある

---

<!--
backgroundColor: black
paginate: false
footer: ""
-->
